model:

training:
  ex_name: "HCI two modality fusion" 
  batch_size: 64
  epochs: 300
  learning_rate: 0.0001
  weight_decay: 0.002
  optimizer: "adam"
  loss_function: "cross_entropy"
  dependent: True
  n_folds: 10
  using_modalities: ['eeg', 'eye', 'pps']


data:
  name: "HCI"
  HCI:
    data_path: "HCI_DATA/hci_data.pkl"
    subject_lists: [1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30]
    modalities: ['eeg', 'eye', 'pps']
    input_size: [960, 38, 230]
    input_dim: 585
    label_type: "arousal"
    num_workers: 4
    ch_nums: 32
    ex_nums: 20

logging:
  log_dir: "/mnt/nvme1/yihaoyuan/Raven/RavenEx/multimodal_emotion_recognition/logs"
  model_dir: "/mnt/nvme1/yihaoyuan/Raven/RavenEx/multimodal_emotion_recognition/outputs"
  save_best_only: True

device:
  gpu: True
  gpu_ids: [0]

seed: 42
num_classes: 3